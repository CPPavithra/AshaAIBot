{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGmD1o5uTWV4",
        "outputId": "64e234ec-2b40-48bb-e6a3-33c02eba18fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests pandas transformers datasets torch scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec==2025.3.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VRiyDGKUjk4",
        "outputId": "d2ce2393-909b-40da-ba67-20394174b6d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2025.3.0\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec==2024.12.0 datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl_vq6KcUx-T",
        "outputId": "a46a31ec-b992-47f5-c304-cd341839201e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2024.12.0\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqbKRUAoWcwY",
        "outputId": "af7bd702-2153-48e5-fa22-9ff897c845c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'cleaned_resume_data.csv', 'pwc', 'resume_data', 'cleaned_linkedin_skills.csv', 'job_matching_ready_jobs.csv', 'job_matching_ready_linkedin_skills.csv', 'job_matching_ready_resumes.csv', 'job_matching_ready_linkedin_postings.csv', 'linkedin_job_postings.csv', 'job_skills.csv', 'job_summary.csv', 'pwc.zip', 'cleaned_linkedin_postings.csv', 'cleaned_google_jobs_data.csv', 'resume.zip', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"resume.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"resume_data\")\n",
        "\n",
        "with zipfile.ZipFile(\"pwc.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"pwc\")\n"
      ],
      "metadata": {
        "id": "b3wxppOfXNTS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"resume_data\"))  #resume data\n",
        "print(os.listdir(\"pwc\"))  #pwc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMzwTPS6XaD_",
        "outputId": "04018433-69fc-406f-ae08-fa3fca6d353f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['resume_data.csv']\n",
            "['03 Diversity-Inclusion-Dataset.xlsx', '.ipynb_checkpoints', 'diversityinclusion.xlsx', 'Diversity-Inclusion.pbix']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "resume_df = pd.read_csv(\"/content/resume_data/resume_data.csv\")\n",
        "print(resume_df.head())  #this is to check resume csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S8k4EzgX_Dr",
        "outputId": "d48a7660-66cd-4dfc-9703-d5bc7c1cdf36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  address                                   career_objective  \\\n",
            "0     NaN  Big data analytics working and database wareho...   \n",
            "1     NaN  Fresher looking to join as a data analyst and ...   \n",
            "2     NaN                                                NaN   \n",
            "3     NaN  To obtain a position in a fast-paced business ...   \n",
            "4     NaN  Professional accountant with an outstanding wo...   \n",
            "\n",
            "                                              skills  \\\n",
            "0  ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...   \n",
            "1  ['Data Analysis', 'Data Analytics', 'Business ...   \n",
            "2  ['Software Development', 'Machine Learning', '...   \n",
            "3  ['accounts payables', 'accounts receivables', ...   \n",
            "4  ['Analytical reasoning', 'Compliance testing k...   \n",
            "\n",
            "                        educational_institution_name  \\\n",
            "0  ['The Amity School of Engineering & Technology...   \n",
            "1  ['Delhi University - Hansraj College', 'Delhi ...   \n",
            "2    ['Birla Institute of Technology (BIT), Ranchi']   \n",
            "3  ['Martinez Adult Education, Business Training ...   \n",
            "4                          ['Kent State University']   \n",
            "\n",
            "                                        degree_names     passing_years  \\\n",
            "0                                         ['B.Tech']          ['2019']   \n",
            "1    ['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']  ['2015', '2018']   \n",
            "2                                         ['B.Tech']          ['2018']   \n",
            "3  ['Computer Applications Specialist Certificate...          ['2008']   \n",
            "4            ['Bachelor of Business Administration']            [None]   \n",
            "\n",
            "  educational_results    result_types             major_field_of_studies  \\\n",
            "0             ['N/A']          [None]                    ['Electronics']   \n",
            "1      ['N/A', 'N/A']  ['N/A', 'N/A']      ['Mathematics', 'Statistics']   \n",
            "2             ['N/A']         ['N/A']  ['Electronics/Telecommunication']   \n",
            "3              [None]          [None]          ['Computer Applications']   \n",
            "4            ['3.84']          [None]                     ['Accounting']   \n",
            "\n",
            "                          professional_company_names  ... online_links  \\\n",
            "0                                      ['Coca-COla']  ...          NaN   \n",
            "1                                ['BIB Consultancy']  ...          NaN   \n",
            "2                              ['Axis Bank Limited']  ...          NaN   \n",
            "3  ['Company Name √Ø¬º City , State', 'Company Name...  ...          NaN   \n",
            "4  ['Company Name', 'Company Name', 'Company Name...  ...       [None]   \n",
            "\n",
            "  issue_dates           expiry_dates  \\\n",
            "0         NaN                    NaN   \n",
            "1         NaN                    NaN   \n",
            "2         NaN                    NaN   \n",
            "3         NaN                    NaN   \n",
            "4      [None]  ['February 15, 2021']   \n",
            "\n",
            "                                  Ôªøjob_position_name  \\\n",
            "0                           Senior Software Engineer   \n",
            "1                     Machine Learning (ML) Engineer   \n",
            "2  Executive/ Senior Executive- Trade Marketing, ...   \n",
            "3                     Business Development Executive   \n",
            "4                                Senior iOS Engineer   \n",
            "\n",
            "                            educationaL_requirements experiencere_requirement  \\\n",
            "0  B.Sc in Computer Science & Engineering from a ...          At least 1 year   \n",
            "1  M.Sc in Computer Science & Engineering or in a...       At least 5 year(s)   \n",
            "2            Master of Business Administration (MBA)         At least 3 years   \n",
            "3                                    Bachelor/Honors             1 to 3 years   \n",
            "4      Bachelor of Science (BSc) in Computer Science         At least 4 years   \n",
            "\n",
            "      age_requirement                                 responsibilities.1  \\\n",
            "0                 NaN  Technical Support\\nTroubleshooting\\nCollaborat...   \n",
            "1                 NaN  Machine Learning Leadership\\nCross-Functional ...   \n",
            "2                 NaN  Trade Marketing Executive\\nBrand Visibility, S...   \n",
            "3  Age 22 to 30 years  Apparel Sourcing\\nQuality Garment Sourcing\\nRe...   \n",
            "4                 NaN  iOS Lifecycle\\nRequirement Analysis\\nNative Fr...   \n",
            "\n",
            "                                     skills_required matched_score  \n",
            "0                                                NaN      0.850000  \n",
            "1                                                NaN      0.750000  \n",
            "2  Brand Promotion\\nCampaign Management\\nField Su...      0.416667  \n",
            "3  Fast typing skill\\nIELTSInternet browsing & on...      0.760000  \n",
            "4  iOS\\niOS App Developer\\niOS Application Develo...      0.650000  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list\n",
        "!kaggle datasets download -d asaniczka/1-3m-linkedin-jobs-and-skills-2024 --unzip -p /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "eScKLwXBYSS2",
        "outputId": "9abadf1d-72b0-42dc-e0b5-f6882d585116"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d57b2529-15a8-455d-981b-ac7b103984c3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d57b2529-15a8-455d-981b-ac7b103984c3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                         title                                               size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  --------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "atharvasoundankar/chocolate-sales                           Chocolate Sales Data üìäüç´                            14473  2025-03-19 03:51:40.270000          17006        290  1.0              \n",
            "adilshamim8/student-depression-dataset                      Student Depression Dataset                        467020  2025-03-13 03:12:30.423000           8235        123  1.0              \n",
            "khushikyad001/fake-news-detection                           Fake News Detection                               182101  2025-03-23 03:29:28.860000            944         24  1.0              \n",
            "monicahjones/steps-tracker-dataset                          steps_tracker_dataset                               9043  2025-03-07 08:36:03.750000           1526         22  1.0              \n",
            "abdulmalik1518/mobiles-dataset-2025                         Mobiles Dataset (2025)                             20314  2025-02-18 06:50:24.370000          20816        329  1.0              \n",
            "ak0212/average-daily-screen-time-for-children               Average Daily Screen Time for Children              1378  2025-03-24 03:52:51.137000           2276         41  1.0              \n",
            "mohamedsaad254/uae-used-cars-analysis-full-project-v1-0     UAE Used Cars Analysis - Full Project v1.0      17351496  2025-03-10 00:38:45.553000           1213         27  1.0              \n",
            "atharvasoundankar/global-cybersecurity-threats-2015-2024    üåê Global Cybersecurity Threats (2015-2024)         48178  2025-03-16 04:23:13.343000           2826         55  1.0              \n",
            "khushikyad001/indian-traffic-violation                      Indian Traffic Violation                          168168  2025-03-27 04:18:21.817000           1477         31  1.0              \n",
            "willianoliveiragibin/games-and-students                     Games and Students                                  5061  2025-03-19 22:20:00.723000           1377         30  1.0              \n",
            "atharvasoundankar/global-housing-market-analysis-2015-2024  üè° Global Housing Market Analysis (2015-2024)       18363  2025-03-18 05:21:22.723000           1551         28  1.0              \n",
            "samayashar/billboard-top-songs                              Billboard Top Songs üé∂                             147043  2025-03-19 12:05:49.107000           1511         27  1.0              \n",
            "albertobircoci/historical-prices-of-major-natural-resource  Historical Prices of Major Natural Resource       266218  2025-04-02 04:54:54.640000            729         25  1.0              \n",
            "baddu01/ipl-2025-player-lifetime-statistics                 IPL 2025 - Player Lifetime Statistics              31187  2025-03-15 17:03:46.937000           1801         23  1.0              \n",
            "zahidmughal2343/employee-data                               Employee Data                                     379143  2025-03-08 19:36:42.953000           2819         43  1.0              \n",
            "mahmoudelhemaly/students-grading-dataset                    Student Performance & Behavior Dataset            520428  2025-02-17 17:38:46.653000          13935        204  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                       Melbourne Housing Snapshot                        461423  2018-06-05 12:52:24.087000         175352       1593  0.7058824        \n",
            "ashu009/person-collecting-waste-coco-dataset                Person-Collecting-Waste COCO Dataset            19854259  2025-03-31 09:50:44.723000            173         22  1.0              \n",
            "ak0212/anxiety-and-depression-mental-health-factors         Anxiety and Depression Mental Health Factors       21687  2025-03-14 13:03:23.933000           2162         38  1.0              \n",
            "saikalbatyrbekova/korean-dramas-dataset-eda                 Korean Dramas Dataset                             111323  2025-03-16 10:52:14.780000            944         26  1.0              \n",
            "Dataset URL: https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024\n",
            "License(s): ODC Attribution License (ODC-By)\n",
            "/content/\n",
            "/content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "linkedinskills_df = pd.read_csv(\"/content/job_skills.csv\")\n",
        "print(linkedinskills_df.head())\n",
        "linkedinsummary_df = pd.read_csv(\"/content/job_summary.csv\")\n",
        "print(linkedinsummary_df.head())\n",
        "linkedinposting_df = pd.read_csv(\"/content/linkedin_job_postings.csv\")\n",
        "print(linkedinposting_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTEutjLpgv6P",
        "outputId": "3ece481e-8d59-402b-d457-a750ce9ad02e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            job_link  \\\n",
            "0  https://www.linkedin.com/jobs/view/housekeeper...   \n",
            "1  https://www.linkedin.com/jobs/view/assistant-g...   \n",
            "2  https://www.linkedin.com/jobs/view/school-base...   \n",
            "3  https://www.linkedin.com/jobs/view/electrical-...   \n",
            "4  https://www.linkedin.com/jobs/view/electrical-...   \n",
            "\n",
            "                                          job_skills  \n",
            "0  Building Custodial Services, Cleaning, Janitor...  \n",
            "1  Customer service, Restaurant management, Food ...  \n",
            "2  Applied Behavior Analysis (ABA), Data analysis...  \n",
            "3  Electrical Engineering, Project Controls, Sche...  \n",
            "4  Electrical Assembly, Point to point wiring, St...  \n",
            "                                            job_link  \\\n",
            "0  https://www.linkedin.com/jobs/view/restaurant-...   \n",
            "1  https://www.linkedin.com/jobs/view/med-surg-re...   \n",
            "2  https://www.linkedin.com/jobs/view/registered-...   \n",
            "3  https://uk.linkedin.com/jobs/view/commercial-a...   \n",
            "4  https://www.linkedin.com/jobs/view/store-manag...   \n",
            "\n",
            "                                         job_summary  \n",
            "0  Rock N Roll Sushi is hiring a Restaurant Manag...  \n",
            "1  Schedule\\n: PRN is required minimum 12 hours p...  \n",
            "2  Description\\nIntroduction\\nAre you looking for...  \n",
            "3  Commercial account executive\\nSheffield\\nFull ...  \n",
            "4  Address:\\nUSA-CT-Newington-44 Fenn Road\\nStore...  \n",
            "                                            job_link  \\\n",
            "0  https://www.linkedin.com/jobs/view/account-exe...   \n",
            "1  https://www.linkedin.com/jobs/view/registered-...   \n",
            "2  https://www.linkedin.com/jobs/view/restaurant-...   \n",
            "3  https://www.linkedin.com/jobs/view/independent...   \n",
            "4  https://www.linkedin.com/jobs/view/group-unit-...   \n",
            "\n",
            "             last_processed_time got_summary got_ner is_being_worked  \\\n",
            "0   2024-01-21 07:12:29.00256+00           t       t               f   \n",
            "1   2024-01-21 07:39:58.88137+00           t       t               f   \n",
            "2  2024-01-21 07:40:00.251126+00           t       t               f   \n",
            "3  2024-01-21 07:40:00.308133+00           t       t               f   \n",
            "4  2024-01-19 09:45:09.215838+00           f       f               f   \n",
            "\n",
            "                                           job_title  \\\n",
            "0  Account Executive - Dispensing (NorCal/Norther...   \n",
            "1                 Registered Nurse - RN Care Manager   \n",
            "2               RESTAURANT SUPERVISOR - THE FORKLIFT   \n",
            "3                      Independent Real Estate Agent   \n",
            "4  Group/Unit Supervisor (Systems Support Manager...   \n",
            "\n",
            "                        company          job_location  first_seen  \\\n",
            "0                            BD         San Diego, CA  2024-01-15   \n",
            "1             Trinity Health MI     Norton Shores, MI  2024-01-14   \n",
            "2       Wasatch Adaptive Sports             Sandy, UT  2024-01-14   \n",
            "3    Howard Hanna | Rand Realty  Englewood Cliffs, NJ  2024-01-16   \n",
            "4  IRS, Office of Chief Counsel          Chamblee, GA  2024-01-17   \n",
            "\n",
            "   search_city search_country                       search_position  \\\n",
            "0     Coronado  United States                           Color Maker   \n",
            "1  Grand Haven  United States              Director Nursing Service   \n",
            "2       Tooele  United States                              Stand-In   \n",
            "3    Pinehurst  United States                     Real-Estate Clerk   \n",
            "4      Gadsden  United States  Supervisor Travel-Information Center   \n",
            "\n",
            "    job_level job_type  \n",
            "0  Mid senior   Onsite  \n",
            "1  Mid senior   Onsite  \n",
            "2  Mid senior   Onsite  \n",
            "3  Mid senior   Onsite  \n",
            "4  Mid senior   Onsite  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "pwc_excel_path = \"/content/pwc/diversityinclusion.xlsx\"\n",
        "\n",
        "if os.path.exists(pwc_excel_path):\n",
        "    pwc_df = pd.read_excel(pwc_excel_path, sheet_name=None)  # Reads all sheets\n",
        "\n",
        "    if pwc_df:  # Ensure sheets exist\n",
        "        print(\"PwC Diversity Sheets Available:\", list(pwc_df.keys()))  # List sheet names\n",
        "\n",
        "        first_sheet = list(pwc_df.keys())[0]  # Get the first sheet name\n",
        "\n",
        "        if not pwc_df[first_sheet].empty:  # Ensure it's not empty\n",
        "            print(\"\\nFirst Sheet Preview:\\n\", pwc_df[first_sheet].head())\n",
        "        else:\n",
        "            print(\"First sheet is empty.\")\n",
        "    else:\n",
        "        print(\"No sheets found in the Excel file.\")\n",
        "else:\n",
        "    print(f\"File not found: {pwc_excel_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd8NUtoEiOiL",
        "outputId": "9c58921b-d9ce-4fba-89eb-847b45040170"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PwC Diversity Sheets Available: ['Pharma Group AG', 'Backing 1', 'Backing 2', 'Backing 3', 'Backing 4']\n",
            "\n",
            "First Sheet Preview:\n",
            "    Employee ID  Gender Job Level after FY20 promotions New hire FY20?  \\\n",
            "0            1    Male              6 - Junior Officer              N   \n",
            "1            2  Female                     4 - Manager              N   \n",
            "2            3    Male                    2 - Director              N   \n",
            "3            4    Male                     4 - Manager              N   \n",
            "4            5  Female              6 - Junior Officer              N   \n",
            "\n",
            "   FY20 Performance Rating Promotion in FY21?  \\\n",
            "0                      2.0                 No   \n",
            "1                      3.0                 No   \n",
            "2                      2.0                 No   \n",
            "3                      3.0                 No   \n",
            "4                      2.0                 No   \n",
            "\n",
            "  In base group for Promotion FY21  Target hire balance FY20 leaver?  \\\n",
            "0                               No                  0.5          Yes   \n",
            "1                              Yes                  0.5           No   \n",
            "2                              Yes                  0.5           No   \n",
            "3                              Yes                  0.5           No   \n",
            "4                              Yes                  0.5           No   \n",
            "\n",
            "  In base group for turnover FY20  ... Promotion in FY20?  \\\n",
            "0                               Y  ...                  N   \n",
            "1                               Y  ...                  N   \n",
            "2                               Y  ...                  N   \n",
            "3                               Y  ...                  N   \n",
            "4                               Y  ...                  N   \n",
            "\n",
            "  FY19 Performance Rating Age group Age @01.07.2020 Nationality 1  \\\n",
            "0                     3.0  30 to 39              37         Spain   \n",
            "1                     NaN  30 to 39              37       Germany   \n",
            "2                     3.0  30 to 39              35   Switzerland   \n",
            "3                     3.0  30 to 39              32       Germany   \n",
            "4                     NaN  20 to 29              28   Switzerland   \n",
            "\n",
            "  Region group: nationality 1 Broad region group: nationality 1  \\\n",
            "0                      Europe                            Europe   \n",
            "1                      Europe                            Europe   \n",
            "2                 Switzerland                       Switzerland   \n",
            "3                      Europe                            Europe   \n",
            "4                 Switzerland                       Switzerland   \n",
            "\n",
            "  Last hire date Years since last hire      Rand  \n",
            "0     2017-04-01                     3  0.177804  \n",
            "1     2017-04-01                     3  0.579315  \n",
            "2     2015-04-01                     5  0.887683  \n",
            "3     2012-04-01                     8  0.053887  \n",
            "4     2019-04-01                     1  0.971681  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwc_excel_path = \"/content/pwc/diversityinclusion.xlsx\"\n",
        "\n",
        "if os.path.exists(pwc_excel_path):\n",
        "    pwc_df = pd.read_excel(pwc_excel_path, sheet_name=None)  # Reads all sheets\n",
        "    print(\"PwC Diversity Sheets Available:\", pwc_df.keys())  # List sheet names\n",
        "    first_sheet = list(pwc_df.keys())[0]\n",
        "    print(\"\\nFirst Sheet Preview:\\n\", pwc_df[first_sheet].head())\n",
        "else:\n",
        "    print(f\"File not found: {pwc_excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciDn3T3MwZw2",
        "outputId": "d6160d7d-ccc6-420c-96a1-06c0359249ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PwC Diversity Sheets Available: dict_keys(['Pharma Group AG', 'Backing 1', 'Backing 2', 'Backing 3', 'Backing 4'])\n",
            "\n",
            "First Sheet Preview:\n",
            "    Employee ID  Gender Job Level after FY20 promotions New hire FY20?  \\\n",
            "0            1    Male              6 - Junior Officer              N   \n",
            "1            2  Female                     4 - Manager              N   \n",
            "2            3    Male                    2 - Director              N   \n",
            "3            4    Male                     4 - Manager              N   \n",
            "4            5  Female              6 - Junior Officer              N   \n",
            "\n",
            "   FY20 Performance Rating Promotion in FY21?  \\\n",
            "0                      2.0                 No   \n",
            "1                      3.0                 No   \n",
            "2                      2.0                 No   \n",
            "3                      3.0                 No   \n",
            "4                      2.0                 No   \n",
            "\n",
            "  In base group for Promotion FY21  Target hire balance FY20 leaver?  \\\n",
            "0                               No                  0.5          Yes   \n",
            "1                              Yes                  0.5           No   \n",
            "2                              Yes                  0.5           No   \n",
            "3                              Yes                  0.5           No   \n",
            "4                              Yes                  0.5           No   \n",
            "\n",
            "  In base group for turnover FY20  ... Promotion in FY20?  \\\n",
            "0                               Y  ...                  N   \n",
            "1                               Y  ...                  N   \n",
            "2                               Y  ...                  N   \n",
            "3                               Y  ...                  N   \n",
            "4                               Y  ...                  N   \n",
            "\n",
            "  FY19 Performance Rating Age group Age @01.07.2020 Nationality 1  \\\n",
            "0                     3.0  30 to 39              37         Spain   \n",
            "1                     NaN  30 to 39              37       Germany   \n",
            "2                     3.0  30 to 39              35   Switzerland   \n",
            "3                     3.0  30 to 39              32       Germany   \n",
            "4                     NaN  20 to 29              28   Switzerland   \n",
            "\n",
            "  Region group: nationality 1 Broad region group: nationality 1  \\\n",
            "0                      Europe                            Europe   \n",
            "1                      Europe                            Europe   \n",
            "2                 Switzerland                       Switzerland   \n",
            "3                      Europe                            Europe   \n",
            "4                 Switzerland                       Switzerland   \n",
            "\n",
            "  Last hire date Years since last hire      Rand  \n",
            "0     2017-04-01                     3  0.177804  \n",
            "1     2017-04-01                     3  0.579315  \n",
            "2     2015-04-01                     5  0.887683  \n",
            "3     2012-04-01                     8  0.053887  \n",
            "4     2019-04-01                     1  0.971681  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_pwc_df = pd.concat(pwc_df.values(), ignore_index=True)\n",
        "print(combined_pwc_df.shape)  # Check total rows and columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VW2nQ2Xqq0Y",
        "outputId": "5fe04289-9fef-4a08-9e72-c6a80ec43498"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1540, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NzzQae1njEi",
        "outputId": "7174fb2e-3dcf-4751-8dad-e9e5439057db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=9ef327f119ceddf4274e0a021486d103b86ab03fbe60734404f6052e278e97de\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "print(\"SerpAPI is working correctly!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk86pA2Cnrx0",
        "outputId": "c52947bb-21a9-4960-df13-45e2bd345a34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SerpAPI is working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "# SerpAPI Key (Replace with your actual key)\n",
        "SERP_API_KEY = \"4e416c8febcb1c2a68d57622025263c30949ba9fec57ac7a782933d2dfd17981\"\n",
        "\n",
        "def search_google_jobs(user_query, user_location):\n",
        "    \"\"\"\n",
        "    Fetches job listings from Google Jobs using SerpAPI based on user input (job field & location).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"google_jobs\",\n",
        "        \"q\": user_query,\n",
        "        #\"q\": \"Data Scientist\",\n",
        "        \"hl\": \"en\",\n",
        "        \"location\": user_location,\n",
        "        #\"location\": \"India\",\n",
        "        \"api_key\": SERP_API_KEY\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "\n",
        "    jobs = []\n",
        "    if \"jobs_results\" in results:\n",
        "        for job in results[\"jobs_results\"]:\n",
        "            jobs.append({\n",
        "                \"title\": job.get(\"title\", \"N/A\"),\n",
        "                \"company\": job.get(\"company_name\", \"Not provided\"),\n",
        "                \"location\": job.get(\"location\", \"Location not provided\"),\n",
        "                \"description\": job.get(\"description\", \"No description available\"),\n",
        "                \"job_link\": f\"https://www.google.com/search?q={job.get('job_id', '')}\"\n",
        "            })\n",
        "\n",
        "    return jobs\n",
        "\n",
        "# Example: Simulating user input from chatbot\n",
        "user_field = input(\"Enter your field of interest (e.g., Economist, AI Researcher): \")\n",
        "user_location = input(\"Enter your preferred job location (e.g., India, London, Remote): \")\n",
        "\n",
        "\n",
        "#user_field = \"Data Scientist\"  # Replace with input(\"Enter your field of interest: \")\n",
        "#user_location = \"India\"\n",
        "job_results = search_google_jobs(user_field, user_location)\n",
        "\n",
        "# Display the results\n",
        "google_jobs_df = pd.DataFrame(job_results)\n",
        "print(google_jobs_df.head())\n",
        "\n",
        "# Optional: Print job listings in a readable format\n",
        "if job_results:\n",
        "    print(\"\\nüîç Job Recommendations:\\n\")\n",
        "    for idx, job in enumerate(job_results[:5], start=1):  # Show top 5 jobs\n",
        "        print(f\"{idx}. {job['title']} at {job['company']} ({job['location']})\")\n",
        "        print(f\"   üìå Description: {job['description'][:150]}...\")  # Show first 150 chars of description\n",
        "        print(f\"   üîó Apply Here: {job['job_link']}\\n\")\n",
        "else:\n",
        "    print(\"üòû No jobs found. Try a different search!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSpbA0xImKcW",
        "outputId": "c04bbace-f148-448e-ee44-4fb3af2cd2cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your field of interest (e.g., Economist, AI Researcher): AI Researcher\n",
            "Enter your preferred job location (e.g., India, London, Remote): India\n",
            "                                    title                   company  \\\n",
            "0  Research Intern ‚Äì Generative AI Agents               SynergyLabs   \n",
            "1              Lead Researcher - Image AI  Dolby Laboratories, Inc.   \n",
            "2                           AI Researcher             Digital Green   \n",
            "3       Senior Research Scientist (AI/ML)                 NielsenIQ   \n",
            "4            Research Scientist, Language           Google DeepMind   \n",
            "\n",
            "                      location  \\\n",
            "0     Gurugram, Haryana, India   \n",
            "1  Bengaluru, Karnataka, India   \n",
            "2             Karnataka, India   \n",
            "3   Chennai, Tamil Nadu, India   \n",
            "4             Karnataka, India   \n",
            "\n",
            "                                         description  \\\n",
            "0  Job Title: Research Intern ‚Äì Generative AI Age...   \n",
            "1  Join the leader in entertainment innovation an...   \n",
            "2  AI Researcher (Language, Voice and Image)\\n\\nR...   \n",
            "3  Company Description\\n\\nNielsenIQ is a consumer...   \n",
            "4  Research Scientist: Language\\n\\nSnapshot\\n\\nTh...   \n",
            "\n",
            "                                            job_link  \n",
            "0  https://www.google.com/search?q=eyJqb2JfdGl0bG...  \n",
            "1  https://www.google.com/search?q=eyJqb2JfdGl0bG...  \n",
            "2  https://www.google.com/search?q=eyJqb2JfdGl0bG...  \n",
            "3  https://www.google.com/search?q=eyJqb2JfdGl0bG...  \n",
            "4  https://www.google.com/search?q=eyJqb2JfdGl0bG...  \n",
            "\n",
            "üîç Job Recommendations:\n",
            "\n",
            "1. Research Intern ‚Äì Generative AI Agents at SynergyLabs (Gurugram, Haryana, India)\n",
            "   üìå Description: Job Title: Research Intern ‚Äì Generative AI Agents\n",
            "\n",
            "Location: Gurugram\n",
            "\n",
            "Duration: 3-6 months\n",
            "\n",
            "Stipend: INR 15,000/-\n",
            "\n",
            "About Us:\n",
            "\n",
            "We are a technology-dri...\n",
            "   üîó Apply Here: https://www.google.com/search?q=eyJqb2JfdGl0bGUiOiJSZXNlYXJjaCBJbnRlcm4g4oCTIEdlbmVyYXRpdmUgQUkgQWdlbnRzIiwiY29tcGFueV9uYW1lIjoiU3luZXJneUxhYnMiLCJhZGRyZXNzX2NpdHkiOiJHdXJ1Z3JhbSwgSGFyeWFuYSwgSW5kaWEiLCJodGlkb2NpZCI6IlNYcXBFVmNnYnRnd1BvN1VBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lGU1c1a2FXRSIsImhsIjoiZW4ifQ==\n",
            "\n",
            "2. Lead Researcher - Image AI at Dolby Laboratories, Inc. (Bengaluru, Karnataka, India)\n",
            "   üìå Description: Join the leader in entertainment innovation and help us design the future. At Dolby, science meets art, and high tech means more than computer code. A...\n",
            "   üîó Apply Here: https://www.google.com/search?q=eyJqb2JfdGl0bGUiOiJMZWFkIFJlc2VhcmNoZXIgLSBJbWFnZSBBSSIsImNvbXBhbnlfbmFtZSI6IkRvbGJ5IExhYm9yYXRvcmllcywgSW5jLiIsImFkZHJlc3NfY2l0eSI6IkJlbmdhbHVydSwgS2FybmF0YWthLCBJbmRpYSIsImh0aWRvY2lkIjoiNFVlNk9Db1VrQTVrX3d0QkFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSUZTVzVrYVdFIiwiaGwiOiJlbiJ9\n",
            "\n",
            "3. AI Researcher at Digital Green (Karnataka, India)\n",
            "   üìå Description: AI Researcher (Language, Voice and Image)\n",
            "\n",
            "Reports to : AI Director, Technology\n",
            "\n",
            "About Digital Green\n",
            "\n",
            "Digital Green is a pioneer global not for profit...\n",
            "   üîó Apply Here: https://www.google.com/search?q=eyJqb2JfdGl0bGUiOiJBSSBSZXNlYXJjaGVyIiwiY29tcGFueV9uYW1lIjoiRGlnaXRhbCBHcmVlbiIsImFkZHJlc3NfY2l0eSI6Ikthcm5hdGFrYSwgSW5kaWEiLCJodGlkb2NpZCI6IjQxV2xTbWQ5XzQzaXlocmpBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lGU1c1a2FXRSIsImhsIjoiZW4ifQ==\n",
            "\n",
            "4. Senior Research Scientist (AI/ML) at NielsenIQ (Chennai, Tamil Nadu, India)\n",
            "   üìå Description: Company Description\n",
            "\n",
            "NielsenIQ is a consumer intelligence company that delivers the Full View‚Ñ¢, the world‚Äôs most complete and clear understanding of c...\n",
            "   üîó Apply Here: https://www.google.com/search?q=eyJqb2JfdGl0bGUiOiJTZW5pb3IgUmVzZWFyY2ggU2NpZW50aXN0IChBSS9NTCkiLCJjb21wYW55X25hbWUiOiJOaWVsc2VuSVEiLCJhZGRyZXNzX2NpdHkiOiJDaGVubmFpLCBUYW1pbCBOYWR1LCBJbmRpYSIsImh0aWRvY2lkIjoiaXc1c1BUZEdaTmxRV3NiQkFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSUZTVzVrYVdFIiwiaGwiOiJlbiJ9\n",
            "\n",
            "5. Research Scientist, Language at Google DeepMind (Karnataka, India)\n",
            "   üìå Description: Research Scientist: Language\n",
            "\n",
            "Snapshot\n",
            "\n",
            "The Languages team at Google Deepmind India is driven by a mission to make AI more linguistically inclusive. W...\n",
            "   üîó Apply Here: https://www.google.com/search?q=eyJqb2JfdGl0bGUiOiJSZXNlYXJjaCBTY2llbnRpc3QsIExhbmd1YWdlIiwiY29tcGFueV9uYW1lIjoiR29vZ2xlIERlZXBNaW5kIiwiYWRkcmVzc19jaXR5IjoiS2FybmF0YWthLCBJbmRpYSIsImh0aWRvY2lkIjoieFg2V1hJSHBwRS1BX2dBREFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSUZTVzVrYVdFIiwiaGwiOiJlbiJ9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOW COMBINING ALL DATASETS-"
      ],
      "metadata": {
        "id": "rbA7a4Z1oDUD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all variables in your environment\n",
        "import pandas as pd\n",
        "defined_dfs = [var for var in globals() if isinstance(globals()[var], pd.DataFrame)]\n",
        "print(defined_dfs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ihJN5YppZKf",
        "outputId": "8dc9ffec-4d19-4233-8f2e-0b3daf3c1364"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['resume_df', 'linkedinskills_df', 'linkedinsummary_df', 'linkedinposting_df', 'combined_pwc_df', 'google_jobs_df']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"Google Jobs\": google_jobs_df,\n",
        "    \"Resume\": resume_df,\n",
        "    \"LinkedIn Skills\": linkedinskills_df,\n",
        "    \"LinkedIn Summary\": linkedinsummary_df,\n",
        "    \"LinkedIn Posting\": linkedinposting_df,\n",
        "    \"PwC Combined\": combined_pwc_df,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nüìå **{name}** Columns:\\n\")\n",
        "    print(df.columns.tolist())  # Print column names as a list\n",
        "    print(\"\\n\" + \"-\"*80)  # Separator for clarity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ElbaXacq3O8",
        "outputId": "1898931b-8971-4af6-a3be-52024b92d8f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå **Google Jobs** Columns:\n",
            "\n",
            "['title', 'company', 'location', 'description', 'job_link', 'keywords']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **Resume** Columns:\n",
            "\n",
            "['address', 'career_objective', 'skills', 'educational_institution_name', 'degree_names', 'passing_years', 'educational_results', 'result_types', 'major_field_of_studies', 'professional_company_names', 'company_urls', 'start_dates', 'end_dates', 'related_skils_in_job', 'positions', 'locations', 'responsibilities', 'extra_curricular_activity_types', 'extra_curricular_organization_names', 'extra_curricular_organization_links', 'role_positions', 'languages', 'proficiency_levels', 'certification_providers', 'certification_skills', 'online_links', 'issue_dates', 'expiry_dates', '\\ufeffjob_position_name', 'educationaL_requirements', 'experiencere_requirement', 'age_requirement', 'responsibilities.1', 'skills_required', 'matched_score']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Skills** Columns:\n",
            "\n",
            "['job_link', 'job_skills']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Summary** Columns:\n",
            "\n",
            "['job_link', 'job_summary']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Posting** Columns:\n",
            "\n",
            "['job_link', 'last_processed_time', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **PwC Combined** Columns:\n",
            "\n",
            "['Employee ID', 'Gender', 'Job Level after FY20 promotions', 'New hire FY20?', 'FY20 Performance Rating', 'Promotion in FY21?', 'In base group for Promotion FY21', 'Target hire balance', 'FY20 leaver?', 'In base group for turnover FY20', 'Department @01.07.2020', 'Leaver FY', 'Job Level after FY21 promotions', 'Last Department in FY20', 'FTE group', 'Time type', 'Department & JL group PRA status', 'Department & JL group for PRA', 'Job Level group PRA status', 'Job Level group for PRA', 'Time in Job Level @01.07.2020', 'Job Level before FY20 promotions', 'Promotion in FY20?', 'FY19 Performance Rating', 'Age group', 'Age @01.07.2020', 'Nationality 1', 'Region group: nationality 1', 'Broad region group: nationality 1', 'Last hire date', 'Years since last hire', 'Rand', 'RAND', 'GENDER', 'GRADE', 'FUNCTION', 'OC_RATE', 'PERFORM', 'Y_GRADE', 'AGE', 'Y_SERVIC', 'Nationality', 'Rank 2', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 1, 2, 3, 4, 5, 6, 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25']\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbObd6h0ySKZ",
        "outputId": "6b8522d9-2cfb-4bd5-fce3-de0a76fea981"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns for standardization\n",
        "resume_df = resume_df.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"))\n",
        "resume_df = resume_df.drop_duplicates()\n",
        "import ast\n",
        "# Ensure 'skills' is a list by splitting comma-separated values\n",
        "resume_df['skills'] = resume_df['skills'].apply(lambda x: x.split(',') if isinstance(x, str) else [])\n",
        "\n",
        "# Convert to lowercase, remove extra spaces & special characters\n",
        "resume_df['skills'] = resume_df['skills'].apply(lambda x: [skill.strip().lower() for skill in x])\n",
        "\n",
        "# Join skills into a single string for easy matching with job listings\n",
        "resume_df['skills'] = resume_df['skills'].apply(lambda x: \", \".join(x))\n",
        "\n",
        "#standardizing experience and job titles\n",
        "resume_df['positions'] = resume_df['positions'].str.lower().str.strip()\n",
        "resume_df['locations'] = resume_df['locations'].str.lower().str.strip()\n",
        "resume_df['start_dates'] = pd.to_datetime(resume_df['start_dates'], errors='coerce')\n",
        "resume_df['end_dates'] = pd.to_datetime(resume_df['end_dates'], errors='coerce')\n",
        "\n",
        "\n",
        "#GOOGLE JOBS CLEANING\n",
        "google_jobs_df = google_jobs_df.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"))\n",
        "google_jobs_df = google_jobs_df.drop_duplicates()\n",
        "\n",
        "# Handle missing values\n",
        "google_jobs_df.fillna(\"\", inplace=True)\n",
        "\n",
        "# Standardize company & location\n",
        "google_jobs_df['company'] = google_jobs_df['company'].str.lower().str.strip()\n",
        "google_jobs_df['location'] = google_jobs_df['location'].str.lower().str.strip()\n",
        "import re\n",
        "\n",
        "def extract_keywords(description):\n",
        "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', description.lower())  # Extract words with 3+ letters\n",
        "    return \", \".join(set(words))  # Remove duplicates\n",
        "\n",
        "google_jobs_df['keywords'] = google_jobs_df['description'].apply(extract_keywords)\n",
        "\n",
        "# Cleaning job_skills in LinkedIn Skills Dataset\n",
        "linkedinskills_df['job_skills'] = linkedinskills_df['job_skills'].apply(\n",
        "    lambda x: x.split(', ') if isinstance(x, str) else x  # Convert comma-separated string to list\n",
        ")\n",
        "linkedinskills_df['job_skills'] = linkedinskills_df['job_skills'].apply(\n",
        "    lambda x: \", \".join(x) if isinstance(x, list) else \"\"  # Convert list back to string\n",
        ")\n",
        "\n",
        "# Cleaning job_level & job_title in LinkedIn Posting Dataset\n",
        "linkedinposting_df['job_level'] = linkedinposting_df['job_level'].astype(str).str.lower().str.strip()\n",
        "linkedinposting_df['job_title'] = linkedinposting_df['job_title'].astype(str).str.lower().str.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "ofRl4PPHtd6H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert dictionary to DataFrame (if necessary)\n",
        "if isinstance(pwc_df, dict):\n",
        "    pwc_df = pd.concat(pwc_df.values(), ignore_index=True)\n",
        "\n",
        "# Ensure all column names are strings before renaming\n",
        "pwc_df.columns = [str(col) for col in pwc_df.columns]\n",
        "\n",
        "# Rename columns (standardize naming)\n",
        "pwc_df = pwc_df.rename(columns=lambda x: str(x).strip().lower().replace(\" \", \"_\"))\n",
        "\n",
        "# Drop unnecessary columns (if they exist)\n",
        "drop_cols = ['unnamed:_0', 'unnamed:_1', 'unnamed:_2', 'unnamed:_3', 'unnamed:_4']\n",
        "pwc_df = pwc_df.drop(columns=[col for col in drop_cols if col in pwc_df.columns])\n",
        "\n",
        "# Handle job levels (fill missing values)\n",
        "if 'job_level_after_fy20_promotions' in pwc_df.columns and 'job_level_before_fy20_promotions' in pwc_df.columns:\n",
        "    pwc_df['job_level'] = pwc_df['job_level_after_fy20_promotions'].fillna(pwc_df['job_level_before_fy20_promotions'])\n",
        "else:\n",
        "    pwc_df['job_level'] = None  # Handle missing columns safely\n",
        "\n",
        "# Ensure job_level is lowercase and clean\n",
        "if 'job_level' in pwc_df.columns:\n",
        "    pwc_df['job_level'] = pwc_df['job_level'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Convert promotion status to binary (1 = Yes, 0 = No)\n",
        "if 'promotion_in_fy21?' in pwc_df.columns:\n",
        "    pwc_df['promotion_probability'] = pwc_df['promotion_in_fy21?'].map({'Yes': 1, 'No': 0})\n",
        "else:\n",
        "    pwc_df['promotion_probability'] = None  # Handle missing column safely\n",
        "\n",
        "# Fill missing performance ratings with 'Unknown'\n",
        "if 'fy20_performance_rating' in pwc_df.columns:\n",
        "    pwc_df['performance_rating'] = pwc_df['fy20_performance_rating'].fillna('Unknown')\n",
        "else:\n",
        "    pwc_df['performance_rating'] = 'Unknown'  # Default if column is missing\n"
      ],
      "metadata": {
        "id": "qEH4_K3ozdxG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"Google Jobs\": google_jobs_df,\n",
        "    \"Resume\": resume_df,\n",
        "    \"LinkedIn Skills\": linkedinskills_df,\n",
        "    \"LinkedIn Summary\": linkedinsummary_df,\n",
        "    \"LinkedIn Posting\": linkedinposting_df,\n",
        "    \"PwC Combined\": combined_pwc_df,\n",
        "}\n",
        "\n",
        "for name, df in dfs.items():\n",
        "    print(f\"\\nüìå **{name}** Columns:\\n\")\n",
        "    print(df.columns.tolist())  # Print column names as a list\n",
        "    print(\"\\n\" + \"-\"*80)  # Separator for clarity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvh5fliozott",
        "outputId": "03b1e13c-7b09-4fa4-f848-2f9a853cd42a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå **Google Jobs** Columns:\n",
            "\n",
            "['title', 'company', 'location', 'description', 'job_link', 'keywords']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **Resume** Columns:\n",
            "\n",
            "['address', 'career_objective', 'skills', 'educational_institution_name', 'degree_names', 'passing_years', 'educational_results', 'result_types', 'major_field_of_studies', 'professional_company_names', 'company_urls', 'start_dates', 'end_dates', 'related_skils_in_job', 'positions', 'locations', 'responsibilities', 'extra_curricular_activity_types', 'extra_curricular_organization_names', 'extra_curricular_organization_links', 'role_positions', 'languages', 'proficiency_levels', 'certification_providers', 'certification_skills', 'online_links', 'issue_dates', 'expiry_dates', '\\ufeffjob_position_name', 'educationaL_requirements', 'experiencere_requirement', 'age_requirement', 'responsibilities.1', 'skills_required', 'matched_score']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Skills** Columns:\n",
            "\n",
            "['job_link', 'job_skills']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Summary** Columns:\n",
            "\n",
            "['job_link', 'job_summary']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **LinkedIn Posting** Columns:\n",
            "\n",
            "['job_link', 'last_processed_time', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå **PwC Combined** Columns:\n",
            "\n",
            "['Employee ID', 'Gender', 'Job Level after FY20 promotions', 'New hire FY20?', 'FY20 Performance Rating', 'Promotion in FY21?', 'In base group for Promotion FY21', 'Target hire balance', 'FY20 leaver?', 'In base group for turnover FY20', 'Department @01.07.2020', 'Leaver FY', 'Job Level after FY21 promotions', 'Last Department in FY20', 'FTE group', 'Time type', 'Department & JL group PRA status', 'Department & JL group for PRA', 'Job Level group PRA status', 'Job Level group for PRA', 'Time in Job Level @01.07.2020', 'Job Level before FY20 promotions', 'Promotion in FY20?', 'FY19 Performance Rating', 'Age group', 'Age @01.07.2020', 'Nationality 1', 'Region group: nationality 1', 'Broad region group: nationality 1', 'Last hire date', 'Years since last hire', 'Rand', 'RAND', 'GENDER', 'GRADE', 'FUNCTION', 'OC_RATE', 'PERFORM', 'Y_GRADE', 'AGE', 'Y_SERVIC', 'Nationality', 'Rank 2', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 1, 2, 3, 4, 5, 6, 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25']\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ‚úÖ Assume your cleaned data is stored in these DataFrames\n",
        "resume_clean_df = resume_df  # Your cleaned resume data\n",
        "google_jobs_clean_df = google_jobs_df  # Your cleaned job listings\n",
        "\n",
        "# ‚úÖ Save the cleaned data\n",
        "resume_clean_df.to_csv(\"cleaned_resume_data.csv\", index=False)\n",
        "google_jobs_clean_df.to_csv(\"cleaned_google_jobs_data.csv\", index=False)\n",
        "linkedinskills_df.to_csv(\"cleaned_linkedin_skills.csv\", index=False)\n",
        "linkedinposting_df.to_csv(\"cleaned_linkedin_postings.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Cleaned data saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-5yGVRZ5MTx",
        "outputId": "6c354b11-31ff-4ea8-dcbb-1ce8b9cf450a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cleaned data saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucNlzaXn6CAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLEANING STARTS FROM HERE"
      ],
      "metadata": {
        "id": "5lWZWForz5KZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ‚úÖ Load the cleaned datasets\n",
        "resume_clean_df = pd.read_csv(\"cleaned_resume_data.csv\")\n",
        "google_jobs_clean_df = pd.read_csv(\"cleaned_google_jobs_data.csv\")\n",
        "linkedinskills_df = pd.read_csv(\"cleaned_linkedin_skills.csv\")  # Ensure this file exists\n",
        "linkedinposting_df = pd.read_csv(\"cleaned_linkedin_postings.csv\")  # Ensure this file exists\n",
        "\n",
        "# ‚úÖ Debug: Print Column Names\n",
        "print(\"Resume Columns:\", resume_clean_df.columns)\n",
        "print(\"Google Jobs Columns:\", google_jobs_clean_df.columns)\n",
        "print(\"LinkedIn Skills Columns:\", linkedinskills_df.columns)\n",
        "print(\"LinkedIn Posting Columns:\", linkedinposting_df.columns)\n",
        "\n",
        "# ‚úÖ Convert Dates to Years of Experience\n",
        "resume_clean_df[\"start_dates\"] = pd.to_datetime(resume_clean_df[\"start_dates\"], errors=\"coerce\")\n",
        "resume_clean_df[\"end_dates\"] = pd.to_datetime(resume_clean_df[\"end_dates\"], errors=\"coerce\")\n",
        "\n",
        "# Fill missing end dates with today's date (assuming current job)\n",
        "resume_clean_df[\"end_dates\"] = resume_clean_df[\"end_dates\"].fillna(pd.to_datetime(\"today\"))\n",
        "\n",
        "# Calculate experience in years\n",
        "resume_clean_df[\"years_of_experience\"] = (resume_clean_df[\"end_dates\"] - resume_clean_df[\"start_dates\"]).dt.days / 365\n",
        "resume_clean_df[\"years_of_experience\"] = resume_clean_df[\"years_of_experience\"].fillna(0)  # Fill NaN with 0\n",
        "\n",
        "# ‚úÖ Encode Job Levels (Ensure column exists)\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "if \"job_level\" in google_jobs_clean_df.columns:\n",
        "    resume_clean_df[\"job_level_encoded\"] = encoder.fit_transform(resume_clean_df[\"positions\"])\n",
        "    google_jobs_clean_df[\"job_level_encoded\"] = encoder.transform(google_jobs_clean_df[\"job_level\"])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: 'job_level' column not found in Google Jobs Data!\")\n",
        "\n",
        "if \"job_level\" in linkedinposting_df.columns:\n",
        "    linkedinposting_df[\"job_level_encoded\"] = encoder.fit_transform(linkedinposting_df[\"job_level\"])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: 'job_level' column not found in LinkedIn Postings!\")\n",
        "\n",
        "# ‚úÖ Convert Skills into List Format (for Matching)\n",
        "resume_clean_df[\"skills\"] = resume_clean_df[\"skills\"].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
        "\n",
        "if \"job_skills\" in linkedinskills_df.columns:\n",
        "    linkedinskills_df[\"job_skills\"] = linkedinskills_df[\"job_skills\"].apply(\n",
        "        lambda x: x.split(\", \") if isinstance(x, str) else []\n",
        "    )\n",
        "    linkedinskills_df[\"job_skills\"] = linkedinskills_df[\"job_skills\"].apply(\n",
        "        lambda x: \", \".join(x) if isinstance(x, list) else \"\"\n",
        "    )\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: 'job_skills' column not found in LinkedIn Skills Data!\")\n",
        "\n",
        "if \"job_title\" in linkedinposting_df.columns:\n",
        "    linkedinposting_df[\"job_title\"] = linkedinposting_df[\"job_title\"].astype(str).str.lower().str.strip()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: 'job_title' column not found in LinkedIn Postings!\")\n",
        "\n",
        "# ‚úÖ Save Processed Data\n",
        "resume_clean_df.to_csv(\"job_matching_ready_resumes.csv\", index=False)\n",
        "google_jobs_clean_df.to_csv(\"job_matching_ready_jobs.csv\", index=False)\n",
        "linkedinskills_df.to_csv(\"job_matching_ready_linkedin_skills.csv\", index=False)\n",
        "linkedinposting_df.to_csv(\"job_matching_ready_linkedin_postings.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Job Matching Data Ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI-Qbm9j2XHp",
        "outputId": "ca574c83-c6b7-4c56-87bf-02ef0eada709"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Columns: Index(['address', 'career_objective', 'skills', 'educational_institution_name',\n",
            "       'degree_names', 'passing_years', 'educational_results', 'result_types',\n",
            "       'major_field_of_studies', 'professional_company_names', 'company_urls',\n",
            "       'start_dates', 'end_dates', 'related_skils_in_job', 'positions',\n",
            "       'locations', 'responsibilities', 'extra_curricular_activity_types',\n",
            "       'extra_curricular_organization_names',\n",
            "       'extra_curricular_organization_links', 'role_positions', 'languages',\n",
            "       'proficiency_levels', 'certification_providers', 'certification_skills',\n",
            "       'online_links', 'issue_dates', 'expiry_dates', 'Ôªøjob_position_name',\n",
            "       'educational_requirements', 'experiencere_requirement',\n",
            "       'age_requirement', 'responsibilities.1', 'skills_required',\n",
            "       'matched_score'],\n",
            "      dtype='object')\n",
            "Google Jobs Columns: Index(['title', 'company', 'location', 'description', 'job_link', 'keywords'], dtype='object')\n",
            "LinkedIn Skills Columns: Index(['job_link', 'job_skills'], dtype='object')\n",
            "LinkedIn Posting Columns: Index(['job_link', 'last_processed_time', 'got_summary', 'got_ner',\n",
            "       'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen',\n",
            "       'search_city', 'search_country', 'search_position', 'job_level',\n",
            "       'job_type'],\n",
            "      dtype='object')\n",
            "‚ö†Ô∏è Warning: 'job_level' column not found in Google Jobs Data!\n",
            "‚úÖ Job Matching Data Ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Replace 'job_matching_ready_resumes.csv' with the actual filename you need\n",
        "files.download(\"job_matching_ready_resumes.csv\")\n",
        "files.download(\"job_matching_ready_jobs.csv\")\n",
        "files.download(\"job_matching_ready_linkedin_skills.csv\")\n",
        "files.download(\"job_matching_ready_linkedin_postings.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yFJLG9bA82Bu",
        "outputId": "1419f01c-5cb5-40dc-9171-ff4de59ba979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e6f6f028-01bd-44bd-82d5-8b1bbfa72c0d\", \"job_matching_ready_resumes.csv\", 17481798)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1b32e1cc-2d43-4989-93e2-9ec0abdc7cbd\", \"job_matching_ready_jobs.csv\", 72003)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_efc39bf1-ab82-4de8-b51d-acde99cdff9f\", \"job_matching_ready_linkedin_skills.csv\", 672717809)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_50af9dc8-9188-4aa6-ba96-07b09317b93f\", \"job_matching_ready_linkedin_postings.csv\", 383458336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "combined_pwc_df.to_csv(\"cleaned_pwc_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "kV-CXdzG-A1a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# ‚úÖ Download the necessary NLTK resources\n",
        "nltk.download(\"punkt\")  # Download the punkt tokenizer\n",
        "nltk.download(\"wordnet\")  # Download the WordNet data for lemmatization\n",
        "nltk.download(\"stopwords\")  # Download the stopwords data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d04XrUBK_8GW",
        "outputId": "c5f308a4-f3d2-480b-b15c-9ecfe512de8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Modify this path if needed\n"
      ],
      "metadata": {
        "id": "BBwyRHxhCJW3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "785Q2cPACQid",
        "outputId": "c70f1d1e-5d7d-4f46-af9a-bda0102f75b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# ‚úÖ Reset NLTK data path\n",
        "nltk.data.path = ['/root/nltk_data']  # or try '/usr/nltk_data' if this path doesn't work\n",
        "\n",
        "# ‚úÖ Download necessary resources\n",
        "nltk.download('wordnet')  # Lemmatizer\n",
        "nltk.download('stopwords')  # Stopwords\n",
        "\n",
        "# ‚úÖ Initialize NLP tools\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text for AI chatbot and LLM model.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove numbers and punctuation\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "        # Remove extra spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Split text into words\n",
        "        words = text.split()\n",
        "\n",
        "        # Lemmatize words and remove stopwords\n",
        "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "        return \" \".join(words)\n",
        "    return \"\"\n",
        "\n",
        "# ‚úÖ Load the cleaned datasets\n",
        "resume_df = pd.read_csv(\"cleaned_resume_data.csv\")\n",
        "google_jobs_df = pd.read_csv(\"cleaned_google_jobs_data.csv\")\n",
        "pwc_df = pd.read_csv(\"cleaned_pwc_data.csv\")  # PwC data for LLM\n",
        "\n",
        "# ‚úÖ Apply text cleaning on relevant fields\n",
        "resume_df[\"career_objective\"] = resume_df[\"career_objective\"].apply(clean_text)\n",
        "resume_df[\"skills\"] = resume_df[\"skills\"].apply(clean_text)\n",
        "resume_df[\"positions\"] = resume_df[\"positions\"].apply(clean_text)\n",
        "\n",
        "google_jobs_df[\"description\"] = google_jobs_df[\"description\"].apply(clean_text)\n",
        "google_jobs_df[\"keywords\"] = google_jobs_df[\"keywords\"].apply(clean_text)\n",
        "\n",
        "# ‚úÖ Clean PWC data\n",
        "#pwc_df[\"content\"] = pwc_df[\"content\"].apply(clean_text)  # Cleaning PwC textual content\n",
        "\n",
        "# ‚úÖ Save Cleaned Text Data for AI Model & LLM\n",
        "resume_df.to_csv(\"chatbot_ready_resumes.csv\", index=False)\n",
        "google_jobs_df.to_csv(\"chatbot_ready_jobs.csv\", index=False)\n",
        "pwc_df.to_csv(\"llm_ready_pwc_data.csv\", index=False)  # PwC data for LLM\n",
        "\n",
        "print(\"‚úÖ AI Chatbot & LLM Data Ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6MzHsi39XSG",
        "outputId": "910701c4-46d5-446e-ad0f-e6760c988a4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AI Chatbot & LLM Data Ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('chatbot_ready_resumes.csv')\n",
        "files.download('chatbot_ready_jobs.csv')\n",
        "files.download('llm_ready_pwc_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3aFqf7-5EkLg",
        "outputId": "4fce6349-8b87-462d-80c8-74162ccf7b80"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c386ee25-c5f7-4100-a7c5-be8fa8482415\", \"chatbot_ready_resumes.csv\", 15178308)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64e6e6e1-22dc-4b1b-af3a-eaad82ea40b5\", \"chatbot_ready_jobs.csv\", 57734)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c94a048d-a82b-4684-a73a-bb9880d7268e\", \"llm_ready_pwc_data.csv\", 283328)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 3 rows of pwc_df\n",
        "print(pwc_df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMCkd9zDq8d",
        "outputId": "4d8527f2-c3d7-403d-db47-5d14efd3a127"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Employee ID  Gender Job Level after FY20 promotions New hire FY20?  \\\n",
            "0          1.0    Male              6 - Junior Officer              N   \n",
            "1          2.0  Female                     4 - Manager              N   \n",
            "2          3.0    Male                    2 - Director              N   \n",
            "\n",
            "   FY20 Performance Rating Promotion in FY21?  \\\n",
            "0                      2.0                 No   \n",
            "1                      3.0                 No   \n",
            "2                      2.0                 No   \n",
            "\n",
            "  In base group for Promotion FY21  Target hire balance FY20 leaver?  \\\n",
            "0                               No                  0.5          Yes   \n",
            "1                              Yes                  0.5           No   \n",
            "2                              Yes                  0.5           No   \n",
            "\n",
            "  In base group for turnover FY20  ... Unnamed: 16 Unnamed: 17 Unnamed: 18  \\\n",
            "0                               Y  ...         NaN         NaN         NaN   \n",
            "1                               Y  ...         NaN         NaN         NaN   \n",
            "2                               Y  ...         NaN         NaN         NaN   \n",
            "\n",
            "  Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22 Unnamed: 23 Unnamed: 24  \\\n",
            "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
            "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
            "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
            "\n",
            "  Unnamed: 25  \n",
            "0         NaN  \n",
            "1         NaN  \n",
            "2         NaN  \n",
            "\n",
            "[3 rows x 70 columns]\n"
          ]
        }
      ]
    }
  ]
}